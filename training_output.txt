x_train shape: (88184, 100, 100, 1)
y_train shape: (88184,)
Number of images in x_train 88184
Number of images in x_test 22046
WARNING:tensorflow:From C:\Users\grace\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\ops\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 98, 98, 28)        280
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 49, 49, 28)        0
_________________________________________________________________
flatten_1 (Flatten)          (None, 67228)             0
_________________________________________________________________
dense_1 (Dense)              (None, 128)               8605312
_________________________________________________________________
dropout_1 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_2 (Dense)              (None, 278)               35862
=================================================================
Total params: 8,641,454
Trainable params: 8,641,454
Non-trainable params: 0
_________________________________________________________________
2020-07-02 13:28:15.661812: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
Epoch 1/10
88184/88184 [==============================] - 559s 6ms/step - loss: 3.7431 - accuracy: 0.1747
Epoch 2/10
88184/88184 [==============================] - 570s 6ms/step - loss: 3.2075 - accuracy: 0.2452
Epoch 3/10
88184/88184 [==============================] - 571s 6ms/step - loss: 2.8948 - accuracy: 0.2920
Epoch 4/10
88184/88184 [==============================] - 573s 6ms/step - loss: 2.6124 - accuracy: 0.3394
Epoch 5/10
88184/88184 [==============================] - 577s 7ms/step - loss: 2.3257 - accuracy: 0.3927
Epoch 6/10
88184/88184 [==============================] - 572s 6ms/step - loss: 2.0534 - accuracy: 0.4494
Epoch 7/10
88184/88184 [==============================] - 580s 7ms/step - loss: 1.8082 - accuracy: 0.5028
Epoch 8/10
88184/88184 [==============================] - 579s 7ms/step - loss: 1.6073 - accuracy: 0.5533
Epoch 9/10
88184/88184 [==============================] - 570s 6ms/step - loss: 1.4232 - accuracy: 0.5966
Epoch 10/10
88184/88184 [==============================] - 571s 6ms/step - loss: 1.2787 - accuracy: 0.6324
22046/22046 [==============================] - 37s 2ms/step
test loss, test acc: [4.731556985097734, 0.2030300348997116]
Label:  252.0
[[2.28378344e-02 1.74863939e-03 9.08854494e-14 1.69539032e-14
  3.18394452e-02 5.57042425e-03 6.12847904e-15 1.99712720e-02
  1.18414362e-04 1.71481850e-04 1.27735446e-04 2.22688643e-04
  6.58419303e-05 6.83701306e-04 4.48753599e-06 2.54252722e-04
  1.64139092e-05 3.89366642e-06 1.47591481e-05 1.41666605e-05
  1.59616411e-05 7.98035558e-07 1.38442556e-11 1.21586802e-14
  4.13267501e-03 1.32922215e-11 4.22204589e-14 2.02358932e-14
  7.04529881e-02 1.09126419e-13 1.87998641e-14 1.93287999e-13
  2.39852238e-02 6.39979262e-05 5.75546757e-04 7.79149016e-15
  9.33164119e-06 4.62186492e-15 7.64379096e-19 2.11372837e-15
  2.58950572e-09 1.08478385e-12 6.20740207e-16 1.74015679e-06
  8.62275636e-17 5.39400466e-18 1.01461916e-15 1.48084748e-03
  7.07026411e-05 3.57516296e-06 2.99313085e-14 4.14906800e-01
  2.25904719e-16 8.50849000e-14 1.67379045e-12 7.09287750e-12
  8.43977090e-03 8.47611030e-14 5.61230836e-12 1.88328304e-08
  2.31800186e-05 4.21806127e-02 3.20049217e-13 7.68991397e-15
  7.56478403e-05 4.71988280e-13 1.02846063e-15 3.62148602e-03
  6.34929079e-15 2.15113843e-15 7.55335204e-04 5.58227859e-03
  2.12322874e-03 6.13443873e-09 6.11301175e-07 1.77542512e-11
  4.09869751e-12 1.32073408e-10 1.70531648e-03 1.92803024e-10
  4.30353219e-03 3.65267852e-06 4.42980417e-16 1.42816803e-03
  2.68151607e-14 2.34296089e-16 6.72946236e-17 1.38268184e-14
  2.69694867e-15 1.64126762e-14 1.32099496e-08 1.56000294e-14
  1.67346923e-04 1.27715384e-13 1.55255804e-03 3.20498572e-07
  2.37705521e-07 1.27829056e-15 3.86542708e-11 3.19756307e-02
  2.93260091e-03 4.04167222e-04 9.91715407e-15 1.53590494e-03
  4.82295263e-06 7.86721003e-13 3.72117297e-16 8.39604239e-04
  6.47205137e-11 1.09972130e-15 1.83312838e-15 2.20403867e-18
  2.81822067e-05 6.66848326e-04 9.47153289e-03 1.36748585e-10
  8.44424765e-04 2.68826912e-15 1.92666950e-18 8.18061759e-04
  1.93523796e-04 9.43857555e-14 1.79852782e-06 3.18787477e-13
  2.70295050e-03 2.00890777e-13 1.75219429e-05 1.24620273e-14
  1.87620855e-04 4.14222619e-03 1.27065025e-04 1.54955673e-03
  1.13557950e-02 7.51678890e-05 1.66402967e-03 2.00051531e-20
  3.23809345e-14 1.31048375e-06 2.32676323e-09 1.39682069e-14
  4.78598842e-04 5.35444298e-04 4.80948342e-03 1.18879592e-02
  7.70490477e-11 4.66068753e-13 1.57648022e-03 2.24824920e-02
  2.24822716e-09 1.55792989e-07 1.28044732e-12 1.32143541e-05
  7.53922173e-15 2.86187567e-12 5.04735144e-05 3.43861431e-02
  3.73568007e-04 5.02356273e-12 4.08260821e-05 1.34345721e-02
  6.33256807e-14 2.17633846e-04 1.15940460e-13 3.90911169e-15
  4.77380581e-06 4.88890900e-16 1.27073989e-04 1.26263774e-06
  2.12447648e-03 9.92402827e-10 3.71285656e-04 1.46424361e-02
  9.96711286e-13 1.06709660e-04 1.39614997e-06 3.53903015e-04
  7.07123545e-05 3.03844083e-03 1.39317092e-13 1.87970042e-13
  1.03121973e-03 1.05220355e-11 6.91353753e-02 3.86850747e-16
  1.11859002e-14 1.88742147e-03 9.21110298e-15 2.79273918e-05
  7.73453675e-13 1.12110865e-03 1.02370491e-11 1.31419592e-03
  3.72793409e-03 5.27458591e-03 6.26111214e-05 1.31234454e-10
  5.09186008e-04 2.03516564e-15 1.00426822e-08 2.44002821e-12
  7.79757393e-04 2.34091021e-05 1.08936524e-06 6.63977051e-09
  1.99432316e-06 3.40210823e-20 2.75267939e-05 3.80986421e-07
  3.75597767e-04 1.07150584e-12 9.25217397e-17 4.24594077e-07
  2.31068029e-11 3.22044325e-05 1.72322842e-07 1.00847919e-05
  1.01655175e-03 2.19279354e-06 5.91529184e-04 1.52118328e-05
  3.03641427e-05 1.16220524e-03 4.89895865e-06 2.25706990e-05
  2.67905679e-14 2.15102909e-06 1.09585535e-05 9.50418238e-04
  7.82867403e-07 1.50037285e-05 6.18440390e-04 6.76625120e-08
  1.32388214e-13 2.81371995e-05 4.18534357e-04 1.45798910e-03
  3.45959980e-03 1.82822124e-09 3.40610184e-03 4.84497473e-03
  2.03571294e-19 7.01570285e-15 1.82935855e-05 1.61002860e-11
  4.93835621e-08 2.03878391e-14 2.56468268e-13 6.36487252e-11
  6.09434324e-13 2.86612300e-14 2.28386544e-14 1.45667345e-09
  8.06714967e-03 3.76910485e-08 1.39234384e-04 2.72229743e-12
  8.97724590e-07 7.96701016e-09 1.86095868e-08 5.49913326e-04
  3.06353793e-02 1.94625027e-05 8.70254202e-10 7.36603653e-15
  3.90769306e-16 2.22235399e-15 9.93489957e-10 1.24553189e-04
  9.85900260e-05 1.24566579e-10 2.36103285e-14 3.28499482e-05
  2.91199028e-03 6.88357672e-15 5.22199465e-16 2.28766249e-18
  1.71023522e-15 1.30588658e-15]]
51
